{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph matrix subspace checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ[\"MKL_NUM_THREADS\"] = \"4\" \n",
    "#os.environ[\"NUMEXPR_NUM_THREADS\"] = \"4\" \n",
    "#os.environ[\"OMP_NUM_THREADS\"] = \"4\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. First results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import os\n",
    "import datetime\n",
    "from pprint import pprint\n",
    "\n",
    "from graph_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rank_and_nullspace(A, get_cutoff_dif=False):\n",
    "    \n",
    "    _, v, d = sp.linalg.svd(A, lapack_driver=\"gesdd\")\n",
    "        \n",
    "    # такой выбор толеранса используется в матлабе и в нампае\n",
    "    # https://numpy.org/doc/stable/reference/generated/numpy.linalg.matrix_rank.html\n",
    "    tol = v.max() * max(A.shape) * np.finfo(A.dtype).eps\n",
    "    nnz = (v >= tol).sum()\n",
    "    \n",
    "    if get_cutoff_dif == False:\n",
    "        return nnz, d[nnz:].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def a_is_subspace_of_b(basis_a, basis_b, get_cutoff=False):\n",
    "    \n",
    "    orig_rank, _ = get_rank_and_nullspace(basis_b)\n",
    "    combined_rank, _ = get_rank_and_nullspace(np.hstack([basis_a, basis_b]))\n",
    "    \n",
    "    return orig_rank == combined_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_chain_starts(basis_set):\n",
    "    \n",
    "    # Sort by the dimensionality of subspaces\n",
    "    basis_set = sorted(basis_set, key=lambda x: x[1])\n",
    "    chain_starts = [basis_set[0]]\n",
    "    \n",
    "    # Go over basis sets and check whether their spaces are subspaces of some of chain_starts spaces\n",
    "    for i in range(1, len(basis_set)):\n",
    "        \n",
    "        not_a_subspace = True\n",
    "        \n",
    "        for start in chain_starts:\n",
    "            if a_is_subspace_of_b(basis_set[i][2], start[2]):\n",
    "                not_a_subspace = False\n",
    "                break\n",
    "        \n",
    "        if not_a_subspace:\n",
    "            chain_starts.append(basis_set[i])\n",
    "    \n",
    "    return chain_starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for an online version of an algorithm\n",
    "# chain_starts are supposed to be sorted by x[1]\n",
    "\n",
    "def get_new_starts(chain_starts, new_basis):\n",
    "    \n",
    "    if len(chain_starts) == 0:\n",
    "        chain_starts.append(new_basis)\n",
    "        return\n",
    "    \n",
    "    checked_pos = 0\n",
    "    \n",
    "    # check if we are embedded in some space\n",
    "    while checked_pos < len(chain_starts) and len(chain_starts[checked_pos][2][0]) >= len(new_basis[2][0]):\n",
    "        if a_is_subspace_of_b(new_basis[2], chain_starts[checked_pos][2]):\n",
    "            return\n",
    "        checked_pos += 1\n",
    "    \n",
    "    # new basis is not embedded anywhere therefore we insert it\n",
    "    chain_starts.insert(checked_pos, new_basis)\n",
    "    checked_pos += 1\n",
    "    \n",
    "    # now we delete subspaces, that are embedded into a new one\n",
    "    while checked_pos < len(chain_starts):\n",
    "        if a_is_subspace_of_b(chain_starts[checked_pos][2], new_basis[2]):\n",
    "            chain_starts.pop(checked_pos)\n",
    "        else:\n",
    "            checked_pos += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ALL_GRAPHS = get_graphs()\n",
    "del ALL_GRAPHS['cycle']\n",
    "\n",
    "# ALL_GRAPHS = {x: ALL_GRAPHS[x] for x in ['center', 'sinking_ship']}\n",
    "# что-то в center баг какой-то 'sinking_ship'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "NON_EQUIV = True\n",
    "\n",
    "for name, g in ALL_GRAPHS.items():\n",
    "    \n",
    "    print(name)\n",
    "    I = find_stable_sets(g)\n",
    "    A, var_matr, num_params = build_triple_equalities(I, g.shape[0])\n",
    "    \n",
    "    num_combs = total_num_of_combinations(I, var_matr, num_params, only_nonequivalent=NON_EQUIV)\n",
    "    \n",
    "    chain_starts = []\n",
    "    \n",
    "    for i, (addA, addB, opening) in tqdm(enumerate(build_variance_equalities_iterator(\n",
    "            I, var_matr, num_params, only_nonequivalent=NON_EQUIV)), total=num_combs):\n",
    "        rank, null_basis = get_rank_and_nullspace(np.array(A + addA, dtype=np.float64))\n",
    "        if len(null_basis) != 0:\n",
    "            get_new_starts(chain_starts, [i, rank, null_basis, opening])\n",
    "    \n",
    "    print(\"{} x {}\".format(len(A), len(A[0])), \"{} x {}\".format(len(addA), len(addA[0])))\n",
    "    print(len(chain_starts), \"dimensions:\", \",\".join([str(len(x[2][0])) for x in chain_starts]))\n",
    "    \n",
    "    print(\"openings:\")\n",
    "    for x in chain_starts: \n",
    "        pprint(x[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Speed optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ALL_GRAPHS = {'dupl': ALL_GRAPHS['dupl'], 'zigzag': ALL_GRAPHS['zigzag'], 'fork': ALL_GRAPHS['fork'], \n",
    "              'big_triag': ALL_GRAPHS['big_triag'], 'big_zig': ALL_GRAPHS['big_zig']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# storm has multiple bases\n",
    "# ship stil doesn't cut it.. we'll have to try more cores\n",
    "\n",
    "# if you simply switch lapack driver to gesvd - results don't change but it takes twice longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for name, g in ALL_GRAPHS.items():\n",
    "\n",
    "    print(name)\n",
    "    I = find_stable_sets(g)\n",
    "    A, var_matr, num_params = build_triple_equalities(I, g.shape[0])\n",
    "\n",
    "    basis_set = []\n",
    "    for i, addA in enumerate(build_variance_equalities_iterator(I, var_matr, num_params, only_nonequivalent=True)):\n",
    "        basis_set.append([i, *get_rank_and_nullspace(np.array(A + addA[0], dtype=np.float64))])\n",
    "\n",
    "    chain_starts = find_chain_starts(basis_set)\n",
    "\n",
    "    print(\"{} x {}\".format(len(A), len(A[0])), \"{} x {}\".format(len(addA[0]), len(addA[0][0])))\n",
    "    print(len(chain_starts), \"dimensions:\", \",\".join([str(len(x[2][0])) for x in chain_starts]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "storm\n",
      "19 x 45 35 x 45\n",
      "2 dimensions: 7,7\n",
      "CPU times: user 12min 5s, sys: 9.58 s, total: 12min 15s\n",
      "Wall time: 3min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# it has been 2min29sec\n",
    "# with 8 cores it's 2min58sec\n",
    "# with 4 cores it's 3min3sec\n",
    "\n",
    "for name, g in ALL_GRAPHS.items():\n",
    "    \n",
    "    print(name)\n",
    "    I = find_stable_sets(g)\n",
    "    A, var_matr, num_params = build_triple_equalities(I, g.shape[0])\n",
    "    \n",
    "    chain_starts = []\n",
    "    for i, addA in enumerate(build_variance_equalities_iterator(I, var_matr, num_params, only_nonequivalent=True)):\n",
    "        chain_starts.append([i, *get_rank_and_nullspace(np.array(A + addA[0], dtype=np.float64))])\n",
    "        chain_starts = find_chain_starts(chain_starts)\n",
    "    \n",
    "    print(\"{} x {}\".format(len(A), len(A[0])), \"{} x {}\".format(len(addA[0]), len(addA[0][0])))\n",
    "    print(len(chain_starts), \"dimensions:\", \",\".join([str(len(x[2][0])) for x in chain_starts]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "storm\n",
      "19 x 45 35 x 45\n",
      "2 dimensions: 7,7\n",
      "CPU times: user 17min 15s, sys: 16.3 s, total: 17min 32s\n",
      "Wall time: 2min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "maxdif = 1e-19\n",
    "\n",
    "for name, g in ALL_GRAPHS.items():\n",
    "    \n",
    "    print(name)\n",
    "    I = find_stable_sets(g)\n",
    "    A, var_matr, num_params = build_triple_equalities(I, g.shape[0])\n",
    "    \n",
    "    chain_starts = []\n",
    "    for i, addA in enumerate(build_variance_equalities_iterator(I, var_matr, num_params, only_nonequivalent=True)):\n",
    "        \n",
    "        matrix = np.array(A + addA[0], dtype=np.float64)\n",
    "        _, v, d = sp.linalg.svd(matrix, lapack_driver=\"gesdd\")\n",
    "        tol = v.max() * max(matrix.shape) * np.finfo(matrix.dtype).eps\n",
    "        nnz = (v >= tol).sum()\n",
    "        \n",
    "        if nnz < len(v):\n",
    "            maxdif = max(v[nnz] / v[nnz-1], maxdif)\n",
    "            \n",
    "        get_new_starts(chain_starts, [i, nnz, d[nnz:].T])\n",
    "    \n",
    "    print(\"{} x {}\".format(len(A), len(A[0])), \"{} x {}\".format(len(addA[0]), len(addA[0][0])))\n",
    "    print(len(chain_starts), \"dimensions:\", \",\".join([str(len(x[2][0])) for x in chain_starts]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### no aplas optimizations\n",
    "\n",
    "mkl is used, 4 cores\n",
    "\n",
    "online (stupid): 1min 32s\n",
    "offline: 1min 18s\n",
    "online (smarter): 1min 25s \n",
    "\n",
    "#### limitting number of cores\n",
    "\n",
    "#os.environ[\"MKL_NUM_THREADS\"] = \"1\" \n",
    "#os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\" \n",
    "#os.environ[\"OMP_NUM_THREADS\"] = \"1\" \n",
    "\n",
    "online (stupid): 1min 33s\n",
    "offline: 1min 20s\n",
    "online (smarter): 1min 26s\n",
    "\n",
    "#### mkl on 8 cores - same result\n",
    "\n",
    "**so online version isn't much slower and number of cores doesn't affect the results much**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Storm analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = ALL_GRAPHS['storm']\n",
    "I = find_stable_sets(g)\n",
    "A, var_matr, num_params = build_triple_equalities(I, g.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А он правильно задан?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_copirr(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "Судя по обсуждениям в интернете - могут быть проблемы при применении gesdd на плохо обсуловленных матрицах - поэтому все эксперименты будем пробовать и с gesdd и gesvd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смотрим на максимальное соотношение между первым отрезанным и неотрезанным с.ч. и минимальное между неотрезанными с.ч. в определении подпространств "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131072/131072 [01:27<00:00, 1493.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.619397193511745e-14 36.66232538729725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "max_cut_dif  = 1e-19\n",
    "max_real_dif = 1e-19\n",
    "min_rank = 1e3\n",
    "\n",
    "total_num = total_num_of_combinations(I, var_matr, num_params, only_nonequivalent=True)\n",
    "\n",
    "for addA, addB, opening in tqdm(\n",
    "    build_variance_equalities_iterator(I, var_matr, num_params, only_nonequivalent=True), total=total_num\n",
    "):\n",
    "\n",
    "    matrix = np.array(A + addA, dtype=np.float64)\n",
    "    _, v, d = sp.linalg.svd(matrix, lapack_driver=\"gesdd\")\n",
    "    tol = v.max() * max(matrix.shape) * np.finfo(matrix.dtype).eps\n",
    "    nnz = (v >= tol).sum()\n",
    "        \n",
    "    if nnz < len(v):\n",
    "        max_cut_dif = max(v[nnz] / v[nnz-1], max_cut_dif)\n",
    "        max_real_dif = max(v[0] / v[nnz-1], max_real_dif)\n",
    "        min_rank = min(nnz, min_rank)\n",
    "        \n",
    "print(max_cut_dif, max_real_dif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(A[0])-min_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/131072 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 50/131072 [00:00<04:25, 492.61it/s]\u001b[A\n",
      "  0%|          | 101/131072 [00:00<04:25, 494.21it/s]\u001b[A\n",
      "  0%|          | 151/131072 [00:00<04:24, 494.46it/s]\u001b[A\n",
      "  0%|          | 200/131072 [00:00<04:25, 492.72it/s]\u001b[A\n",
      "  0%|          | 250/131072 [00:00<04:25, 492.68it/s]\u001b[A\n",
      "  0%|          | 300/131072 [00:00<04:24, 493.65it/s]\u001b[A\n",
      "  0%|          | 350/131072 [00:00<04:25, 492.97it/s]\u001b[A\n",
      "  0%|          | 400/131072 [00:00<04:24, 494.06it/s]\u001b[A\n",
      "  0%|          | 450/131072 [00:00<04:23, 495.26it/s]\u001b[A\n",
      "  0%|          | 500/131072 [00:01<04:23, 495.67it/s]\u001b[A\n",
      "  0%|          | 551/131072 [00:01<04:22, 496.73it/s]\u001b[A\n",
      "  0%|          | 602/131072 [00:01<04:21, 498.34it/s]\u001b[A\n",
      "  0%|          | 652/131072 [00:01<04:22, 497.14it/s]\u001b[A\n",
      "  1%|          | 702/131072 [00:01<04:22, 496.54it/s]\u001b[A\n",
      "  1%|          | 752/131072 [00:01<04:22, 496.02it/s]\u001b[A\n",
      "  1%|          | 802/131072 [00:01<04:22, 495.85it/s]\u001b[A\n",
      "100%|██████████| 131072/131072 [04:23<00:00, 497.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.682405378060707e-15 36.662325387297344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "max_cut_dif  = 1e-19\n",
    "max_real_dif = 1e-19\n",
    "\n",
    "total_num = total_num_of_combinations(I, var_matr, num_params, only_nonequivalent=True)\n",
    "\n",
    "for addA, addB, opening in tqdm(\n",
    "    build_variance_equalities_iterator(I, var_matr, num_params, only_nonequivalent=True), total=total_num\n",
    "):\n",
    "\n",
    "    matrix = np.array(A + addA, dtype=np.float64)\n",
    "    _, v, d = sp.linalg.svd(matrix, lapack_driver=\"gesvd\")\n",
    "    tol = v.max() * max(matrix.shape) * np.finfo(matrix.dtype).eps\n",
    "    nnz = (v >= tol).sum()\n",
    "        \n",
    "    if nnz < len(v):\n",
    "        max_cut_dif = max(v[nnz] / v[nnz-1], max_cut_dif)\n",
    "        max_real_dif = max(v[0] / v[nnz-1], max_real_dif)\n",
    "            \n",
    "print(max_cut_dif, max_real_dif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, найдётся ли среди отфильтрованных нами пространств 8-мерное"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 83446/34359738368 [00:35<4046:52:39, 2358.45it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-ebd7ccdc84a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m ):\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mmatrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0maddA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlapack_driver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"gesdd\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_uv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mtol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "min_rank = 1e3\n",
    "\n",
    "total_num = total_num_of_combinations(I, var_matr, num_params, only_nonequivalent=False)\n",
    "\n",
    "for addA, addB, opening in tqdm(\n",
    "    build_variance_equalities_iterator(I, var_matr, num_params, only_nonequivalent=False), total=total_num\n",
    "):\n",
    "\n",
    "    matrix = np.array(A + addA, dtype=np.float64)\n",
    "    v = sp.linalg.svd(matrix, lapack_driver=\"gesdd\", compute_uv=False)\n",
    "    tol = v.max() * max(matrix.shape) * np.finfo(matrix.dtype).eps\n",
    "    nnz = (v >= tol).sum()\n",
    "    min_rank = min(nnz, min_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну, этого нам не проверить"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
